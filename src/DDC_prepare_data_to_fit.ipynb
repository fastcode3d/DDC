{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FaceDetector:\n",
    "    def __init__(self, \n",
    "                 modelFile=\"../models/res10_300x300_ssd_iter_140000.caffemodel\",\n",
    "                 configFile = \"../models/deploy.prototxt\",\n",
    "                 max_interations = 300,\n",
    "                 conf_threshold = 0.60,\n",
    "                 normalized_dim = (32,32)):\n",
    "        self.modelFile = modelFile\n",
    "        self.configFile = configFile\n",
    "        self.max_interations = max_interations\n",
    "        self.conf_threshold = conf_threshold\n",
    "        self.normalized_dim = normalized_dim\n",
    "        self.net = cv2.dnn.readNetFromCaffe(self.configFile, self.modelFile)\n",
    "        \n",
    "    def extract_random_faces(self, filename, num_faces):\n",
    "        captured_faces = []\n",
    "        iterations = 0\n",
    "        v_cap = cv2.VideoCapture(filename)\n",
    "        v_length = int(v_cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        \n",
    "        while len(captured_faces) < num_faces and iterations < self.max_interations:\n",
    "            iterations += 1\n",
    "            v_cap.set(1, np.random.randint(v_length)-1)\n",
    "            \n",
    "            ret, img = v_cap.read()\n",
    "        \n",
    "            if ret == True:\n",
    "                (h, w) = img.shape[:2]\n",
    "                blob = cv2.dnn.blobFromImage(cv2.resize(img, (300, 300)), 1.0, (300, 300), (103.93, 116.77, 123.68))\n",
    "                self.net.setInput(blob)\n",
    "                detections = self.net.forward()\n",
    "                for i in range(detections.shape[2]):\n",
    "                    confidence = detections[0, 0, i, 2]            \n",
    "                    if confidence > self.conf_threshold:\n",
    "                        box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
    "                        (x1, y1, x2, y2) = box.astype(\"int\")\n",
    "                        face=img[y1:y2, x1:x2]\n",
    "                        \n",
    "                        # normlize\n",
    "                        face = cv2.resize(face, self.normalized_dim)\n",
    "                        captured_faces.append(face)\n",
    "        \n",
    "        # When everything done, release the video capture and video write objects\n",
    "        v_cap.release()\n",
    "    \n",
    "        return captured_faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dfdc_train_part_14\n",
      "dfdc_train_part_48\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "for root, dirs, files in os.walk('../videos', topdown=False):\n",
    "    for name in dirs:\n",
    "        print(name)\n",
    "        dfdir = pd.read_json('../videos/' + name + '/metadata.json')\n",
    "        dfdir = dfdir.T\n",
    "        dfdir['dir'] = name\n",
    "        df = df.append(dfdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>original</th>\n",
       "      <th>split</th>\n",
       "      <th>dir</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4927</td>\n",
       "      <td>4160</td>\n",
       "      <td>4927</td>\n",
       "      <td>4927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2</td>\n",
       "      <td>767</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>FAKE</td>\n",
       "      <td>evpbbjssuo.mp4</td>\n",
       "      <td>train</td>\n",
       "      <td>dfdc_train_part_14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>4160</td>\n",
       "      <td>23</td>\n",
       "      <td>4927</td>\n",
       "      <td>2464</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       label        original  split                 dir\n",
       "count   4927            4160   4927                4927\n",
       "unique     2             767      1                   2\n",
       "top     FAKE  evpbbjssuo.mp4  train  dfdc_train_part_14\n",
       "freq    4160              23   4927                2464"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>original</th>\n",
       "      <th>split</th>\n",
       "      <th>dir</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>wpmnzhcaps.mp4</th>\n",
       "      <td>FAKE</td>\n",
       "      <td>vwpphgpqma.mp4</td>\n",
       "      <td>train</td>\n",
       "      <td>dfdc_train_part_14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adlbyccevz.mp4</th>\n",
       "      <td>FAKE</td>\n",
       "      <td>gsxlolioxh.mp4</td>\n",
       "      <td>train</td>\n",
       "      <td>dfdc_train_part_48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jcaentwavr.mp4</th>\n",
       "      <td>FAKE</td>\n",
       "      <td>jdzkykqgsx.mp4</td>\n",
       "      <td>train</td>\n",
       "      <td>dfdc_train_part_48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mvqelazvsk.mp4</th>\n",
       "      <td>FAKE</td>\n",
       "      <td>dhgvvblxsu.mp4</td>\n",
       "      <td>train</td>\n",
       "      <td>dfdc_train_part_14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>izvqobjehj.mp4</th>\n",
       "      <td>FAKE</td>\n",
       "      <td>tskjnnvjsa.mp4</td>\n",
       "      <td>train</td>\n",
       "      <td>dfdc_train_part_48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cfnbltpvbr.mp4</th>\n",
       "      <td>FAKE</td>\n",
       "      <td>ecpoizyscr.mp4</td>\n",
       "      <td>train</td>\n",
       "      <td>dfdc_train_part_48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fvtdxqdsmv.mp4</th>\n",
       "      <td>FAKE</td>\n",
       "      <td>yvfoaoiclp.mp4</td>\n",
       "      <td>train</td>\n",
       "      <td>dfdc_train_part_48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fdfqweaety.mp4</th>\n",
       "      <td>FAKE</td>\n",
       "      <td>pjpfdrqixm.mp4</td>\n",
       "      <td>train</td>\n",
       "      <td>dfdc_train_part_14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rjzvgihmuu.mp4</th>\n",
       "      <td>REAL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>train</td>\n",
       "      <td>dfdc_train_part_48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bosbcjeizu.mp4</th>\n",
       "      <td>FAKE</td>\n",
       "      <td>hxahnhbnrz.mp4</td>\n",
       "      <td>train</td>\n",
       "      <td>dfdc_train_part_48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               label        original  split                 dir\n",
       "wpmnzhcaps.mp4  FAKE  vwpphgpqma.mp4  train  dfdc_train_part_14\n",
       "adlbyccevz.mp4  FAKE  gsxlolioxh.mp4  train  dfdc_train_part_48\n",
       "jcaentwavr.mp4  FAKE  jdzkykqgsx.mp4  train  dfdc_train_part_48\n",
       "mvqelazvsk.mp4  FAKE  dhgvvblxsu.mp4  train  dfdc_train_part_14\n",
       "izvqobjehj.mp4  FAKE  tskjnnvjsa.mp4  train  dfdc_train_part_48\n",
       "cfnbltpvbr.mp4  FAKE  ecpoizyscr.mp4  train  dfdc_train_part_48\n",
       "fvtdxqdsmv.mp4  FAKE  yvfoaoiclp.mp4  train  dfdc_train_part_48\n",
       "fdfqweaety.mp4  FAKE  pjpfdrqixm.mp4  train  dfdc_train_part_14\n",
       "rjzvgihmuu.mp4  REAL             NaN  train  dfdc_train_part_48\n",
       "bosbcjeizu.mp4  FAKE  hxahnhbnrz.mp4  train  dfdc_train_part_48"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "fd=FaceDetector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:09<00:00,  4.15s/it]\n"
     ]
    }
   ],
   "source": [
    "nr = 3\n",
    "nf = 4\n",
    "faces = np.empty(shape=(0,32,32,3), dtype=np.int8)\n",
    "labels = np.empty(shape=(0, 1), dtype=\"<U5\")\n",
    "for index, row in tqdm(df.sample(nr).iterrows(), total=nr):\n",
    "    images = fd.extract_random_faces('../videos/' + row.dir + '/' + index, nf)\n",
    "    if len(images) > 0:\n",
    "        faces = np.append(faces,images,axis=0)\n",
    "        labels = np.append(labels, np.full(shape=(len(images),1), fill_value=row.label, dtype=\"<U5\"),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(faces) == len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('../data/train',faces=faces, labels=labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
