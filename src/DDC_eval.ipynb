{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./train.npz\n",
      "./.DS_Store\n",
      "./.x.xml.swp\n",
      "./DDC_model\n",
      "./deploy.prototxt\n",
      "./NumPy_tests.ipynb\n",
      "./labels_train.npz\n",
      "./DDC_EDA.ipynb\n",
      "./faces_train.npz\n",
      "./REAL_FAKE_le.pickle\n",
      "./train.json\n",
      "./DDC_prepare_data_to_fit.ipynb\n",
      "./REAL_FAKE_le\n",
      "./DDC_pytorch.ipynb\n",
      "./res10_300x300_ssd_iter_140000.caffemodel\n",
      "./haarcascade_frontalface_default.xml\n",
      "./DDC_DLib.ipynb\n",
      "./DDC_model.ipynb\n",
      "./DDC.model\n",
      "./DDC_eval.ipynb\n",
      "./DDC_cv2_CascadeClassifier.ipynb\n",
      "./DDC_cv2_dnn_res10_300x300_ssd_iter_140000.ipynb\n",
      "./saved_models/DDC_ResNet29v2_model.006.h5\n",
      "./saved_models/DDC_ResNet29v2_model.012.h5\n",
      "./saved_models/DDC_ResNet29v2_model.002.h5\n",
      "./saved_models/DDC_ResNet29v2_model.028.h5\n",
      "./saved_models/DDC_ResNet29v2_model.009.h5\n",
      "./saved_models/DDC_ResNet29v2_model.029.h5\n",
      "./saved_models/DDC_ResNet29v2_model.004.h5\n",
      "./saved_models/DDC_ResNet29v2_model.001.h5\n",
      "./.ipynb_checkpoints/DDC_cv2_dnn_res10_300x300_ssd_iter_140000-checkpoint.ipynb\n",
      "./.ipynb_checkpoints/DDC_eval-checkpoint.ipynb\n",
      "./.ipynb_checkpoints/NumPy_tests-checkpoint.ipynb\n",
      "./.ipynb_checkpoints/DDC_model-checkpoint.ipynb\n",
      "./.ipynb_checkpoints/DDC_pytorch-checkpoint.ipynb\n",
      "./.ipynb_checkpoints/DDC_prepare_data_to_fit-checkpoint.ipynb\n",
      "./.ipynb_checkpoints/DDC_cv2_CascadeClassifier-checkpoint.ipynb\n",
      "./.ipynb_checkpoints/DDC_EDA-checkpoint.ipynb\n",
      "./.ipynb_checkpoints/DDC_DLib-checkpoint.ipynb\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "for dirname, _, filenames in os.walk('.'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt \n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FaceDetector:\n",
    "    def __init__(self, \n",
    "                 modelFile=\"res10_300x300_ssd_iter_140000.caffemodel\",\n",
    "                 configFile = \"deploy.prototxt\",\n",
    "                 max_interations = 300,\n",
    "                 conf_threshold = 0.60,\n",
    "                 normalized_dim = (32,32)):\n",
    "        self.modelFile = modelFile\n",
    "        self.configFile = configFile\n",
    "        self.max_interations = max_interations\n",
    "        self.conf_threshold = conf_threshold\n",
    "        self.normalized_dim = normalized_dim\n",
    "        self.net = cv2.dnn.readNetFromCaffe(self.configFile, self.modelFile)\n",
    "        \n",
    "    def extract_random_faces(self, filename, num_faces):\n",
    "        captured_faces = []\n",
    "        iterations = 0\n",
    "        v_cap = cv2.VideoCapture(filename)\n",
    "        v_length = int(v_cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        \n",
    "        while len(captured_faces) < num_faces and iterations < self.max_interations:\n",
    "            iterations += 1\n",
    "            v_cap.set(1, np.random.randint(v_length)-1)\n",
    "            \n",
    "            ret, img = v_cap.read()\n",
    "        \n",
    "            if ret == True:\n",
    "                (h, w) = img.shape[:2]\n",
    "                blob = cv2.dnn.blobFromImage(cv2.resize(img, (300, 300)), 1.0, (300, 300), (103.93, 116.77, 123.68))\n",
    "                self.net.setInput(blob)\n",
    "                detections = self.net.forward()\n",
    "                for i in range(detections.shape[2]):\n",
    "                    confidence = detections[0, 0, i, 2]            \n",
    "                    if confidence > self.conf_threshold:\n",
    "                        box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
    "                        (x1, y1, x2, y2) = box.astype(\"int\")\n",
    "                        face=img[y1:y2, x1:x2]\n",
    "                        \n",
    "                        # normlize\n",
    "                        face = cv2.resize(face, self.normalized_dim)\n",
    "                        captured_faces.append(face)\n",
    "        \n",
    "        # When everything done, release the video capture and video write objects\n",
    "        v_cap.release()\n",
    "    \n",
    "        return captured_faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../videos/dfdc_train_part_14'\n",
    "modelFile = './saved_models/DDC_ResNet29v2_model.029.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "fd = FaceDetector(max_interations = 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(modelFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(path + '/metadata.json')\n",
    "df = df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['predict'] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>original</th>\n",
       "      <th>split</th>\n",
       "      <th>predict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ffscvgescz.mp4</th>\n",
       "      <td>FAKE</td>\n",
       "      <td>iezlgezozt.mp4</td>\n",
       "      <td>train</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rtnhyhrxny.mp4</th>\n",
       "      <td>FAKE</td>\n",
       "      <td>gdavsauheg.mp4</td>\n",
       "      <td>train</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nrpasaonsc.mp4</th>\n",
       "      <td>FAKE</td>\n",
       "      <td>msegqgxgbb.mp4</td>\n",
       "      <td>train</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sqspjnqhun.mp4</th>\n",
       "      <td>FAKE</td>\n",
       "      <td>kxfuajzzdo.mp4</td>\n",
       "      <td>train</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tpqdixzqqk.mp4</th>\n",
       "      <td>REAL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>train</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pxhzhjufts.mp4</th>\n",
       "      <td>REAL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>train</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vydaidnycn.mp4</th>\n",
       "      <td>FAKE</td>\n",
       "      <td>xhsijmkono.mp4</td>\n",
       "      <td>train</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iqmvrahukb.mp4</th>\n",
       "      <td>FAKE</td>\n",
       "      <td>zyicfdblvi.mp4</td>\n",
       "      <td>train</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wkfjsqzatw.mp4</th>\n",
       "      <td>REAL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>train</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pehzjkpbrd.mp4</th>\n",
       "      <td>FAKE</td>\n",
       "      <td>kyiivwctwe.mp4</td>\n",
       "      <td>train</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               label        original  split  predict\n",
       "ffscvgescz.mp4  FAKE  iezlgezozt.mp4  train      0.0\n",
       "rtnhyhrxny.mp4  FAKE  gdavsauheg.mp4  train      0.0\n",
       "nrpasaonsc.mp4  FAKE  msegqgxgbb.mp4  train      0.0\n",
       "sqspjnqhun.mp4  FAKE  kxfuajzzdo.mp4  train      0.0\n",
       "tpqdixzqqk.mp4  REAL             NaN  train      0.0\n",
       "pxhzhjufts.mp4  REAL             NaN  train      0.0\n",
       "vydaidnycn.mp4  FAKE  xhsijmkono.mp4  train      0.0\n",
       "iqmvrahukb.mp4  FAKE  zyicfdblvi.mp4  train      0.0\n",
       "wkfjsqzatw.mp4  REAL             NaN  train      0.0\n",
       "pehzjkpbrd.mp4  FAKE  kyiivwctwe.mp4  train      0.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:05<00:47,  5.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ksdohprrko.mp4 REAL 0.99737227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 2/10 [00:13<00:48,  6.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kyiivwctwe.mp4 REAL 0.9699591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|███       | 3/10 [00:18<00:40,  5.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ltfagtaafd.mp4 REAL 0.9982341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 4/10 [00:27<00:40,  6.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hwofkxxmyw.mp4 REAL 0.91655254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 5/10 [00:36<00:37,  7.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bzqsxmvxny.mp4 REAL 0.90582645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 6/10 [00:52<00:40, 10.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wpdrxrheoy.mp4 REAL 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|███████   | 7/10 [01:06<00:33, 11.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xdxfmvnghz.mp4 REAL 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████  | 8/10 [01:22<00:25, 12.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wtaghbgiln.mp4 REAL 0.9899476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|█████████ | 9/10 [01:34<00:12, 12.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pxhzhjufts.mp4 REAL 0.9680869\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 10/10 [01:39<00:00, 10.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mbgiqctjzk.mp4 REAL 0.8995999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "nf = 20\n",
    "nf_min = 5\n",
    "n = 10\n",
    "for index, row in tqdm(df.query('label == \"REAL\"').sample(n).iterrows(), total=n):\n",
    "    faces = fd.extract_random_faces(path + '/' + index, nf)\n",
    "    \n",
    "    if len(faces) >= nf_min:\n",
    "        faces = np.append(np.empty(shape=(0,32,32,3), dtype=np.int8), \n",
    "                      faces, \n",
    "                      axis=0)\n",
    "\n",
    "        faces = faces.astype('float32') / 255\n",
    "        faces_mean = np.mean(faces, axis=0)\n",
    "        faces -= faces_mean\n",
    "        predictions = model.predict(faces)\n",
    "        predict = np.mean(predictions[:,0])\n",
    "    else:\n",
    "        predict = .5\n",
    "    \n",
    "    df.at[index, 'predict'] = predict\n",
    "    print(index,row.label,predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>original</th>\n",
       "      <th>split</th>\n",
       "      <th>predict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>xdxfmvnghz.mp4</th>\n",
       "      <td>REAL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>train</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ltfagtaafd.mp4</th>\n",
       "      <td>REAL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>train</td>\n",
       "      <td>0.998234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ksdohprrko.mp4</th>\n",
       "      <td>REAL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>train</td>\n",
       "      <td>0.997372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kyiivwctwe.mp4</th>\n",
       "      <td>REAL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>train</td>\n",
       "      <td>0.969959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pxhzhjufts.mp4</th>\n",
       "      <td>REAL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>train</td>\n",
       "      <td>0.968087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wpdrxrheoy.mp4</th>\n",
       "      <td>REAL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>train</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mbgiqctjzk.mp4</th>\n",
       "      <td>REAL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>train</td>\n",
       "      <td>0.899600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bzqsxmvxny.mp4</th>\n",
       "      <td>REAL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>train</td>\n",
       "      <td>0.905826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hwofkxxmyw.mp4</th>\n",
       "      <td>REAL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>train</td>\n",
       "      <td>0.916553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wtaghbgiln.mp4</th>\n",
       "      <td>REAL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>train</td>\n",
       "      <td>0.989948</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               label original  split   predict\n",
       "xdxfmvnghz.mp4  REAL      NaN  train  0.500000\n",
       "ltfagtaafd.mp4  REAL      NaN  train  0.998234\n",
       "ksdohprrko.mp4  REAL      NaN  train  0.997372\n",
       "kyiivwctwe.mp4  REAL      NaN  train  0.969959\n",
       "pxhzhjufts.mp4  REAL      NaN  train  0.968087\n",
       "wpdrxrheoy.mp4  REAL      NaN  train  0.500000\n",
       "mbgiqctjzk.mp4  REAL      NaN  train  0.899600\n",
       "bzqsxmvxny.mp4  REAL      NaN  train  0.905826\n",
       "hwofkxxmyw.mp4  REAL      NaN  train  0.916553\n",
       "wtaghbgiln.mp4  REAL      NaN  train  0.989948"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.query('predict > 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
