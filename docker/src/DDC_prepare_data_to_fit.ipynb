{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading https://files.pythonhosted.org/packages/74/24/0cdbf8907e1e3bc5a8da03345c23cbed7044330bb8f73bb12e711a640a00/pandas-0.24.2-cp35-cp35m-manylinux1_x86_64.whl (10.0MB)\n",
      "\u001b[K    100% |████████████████████████████████| 10.0MB 153kB/s eta 0:00:01   61% |███████████████████▊            | 6.2MB 18.6MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tqdm\n",
      "  Downloading https://files.pythonhosted.org/packages/8c/c3/d049cf3fb31094ee045ec1ee29fffac218c91e82c8838c49ab4c3e52627b/tqdm-4.41.0-py2.py3-none-any.whl (56kB)\n",
      "\u001b[K    100% |████████████████████████████████| 61kB 9.4MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting matplotlib\n",
      "  Downloading https://files.pythonhosted.org/packages/89/61/465fb3bfba684b0f53b5c4829c3c89e86e6fe9fdcdfda93e38f1788090f0/matplotlib-3.0.3-cp35-cp35m-manylinux1_x86_64.whl (13.0MB)\n",
      "\u001b[K    100% |████████████████████████████████| 13.0MB 121kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.5.0 in /usr/local/lib/python3.5/dist-packages (from pandas)\n",
      "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.5/dist-packages (from pandas)\n",
      "Collecting pytz>=2011k (from pandas)\n",
      "  Downloading https://files.pythonhosted.org/packages/e7/f9/f0b53f88060247251bf481fa6ea62cd0d25bf1b11a87888e53ce5b7c8ad2/pytz-2019.3-py2.py3-none-any.whl (509kB)\n",
      "\u001b[K    100% |████████████████████████████████| 512kB 3.1MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 (from matplotlib)\n",
      "  Downloading https://files.pythonhosted.org/packages/5d/bc/1e58593167fade7b544bfe9502a26dc860940a79ab306e651e7f13be68c2/pyparsing-2.4.6-py2.py3-none-any.whl (67kB)\n",
      "\u001b[K    100% |████████████████████████████████| 71kB 8.8MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting cycler>=0.10 (from matplotlib)\n",
      "  Downloading https://files.pythonhosted.org/packages/f7/d2/e07d3ebb2bd7af696440ce7e754c59dd546ffe1bbe732c8ab68b9c834e61/cycler-0.10.0-py2.py3-none-any.whl\n",
      "Collecting kiwisolver>=1.0.1 (from matplotlib)\n",
      "  Downloading https://files.pythonhosted.org/packages/ee/18/4cd2e84c6aff0c6a50479118083d20b9e676e5175a913c0ea76d700fc244/kiwisolver-1.1.0-cp35-cp35m-manylinux1_x86_64.whl (90kB)\n",
      "\u001b[K    100% |████████████████████████████████| 92kB 7.8MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.5/dist-packages (from python-dateutil>=2.5.0->pandas)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from kiwisolver>=1.0.1->matplotlib)\n",
      "Installing collected packages: pytz, pandas, tqdm, pyparsing, cycler, kiwisolver, matplotlib\n",
      "Successfully installed cycler-0.10.0 kiwisolver-1.1.0 matplotlib-3.0.3 pandas-0.24.2 pyparsing-2.4.6 pytz-2019.3 tqdm-4.41.0\n",
      "\u001b[33mYou are using pip version 9.0.3, however version 19.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Install a pip package in the current Jupyter kernel\n",
    "import sys\n",
    "!{sys.executable} -m pip install pandas tqdm matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "#import pandas as pd\n",
    "import cv2\n",
    "#from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FaceDetector:\n",
    "    def __init__(self, \n",
    "                 modelFile=\"../models/res10_300x300_ssd_iter_140000.caffemodel\",\n",
    "                 configFile = \"../models/deploy.prototxt\",\n",
    "                 max_interations = 300,\n",
    "                 conf_threshold = 0.60,\n",
    "                 normalized_dim = (32,32)):\n",
    "        self.modelFile = modelFile\n",
    "        self.configFile = configFile\n",
    "        self.max_interations = max_interations\n",
    "        self.conf_threshold = conf_threshold\n",
    "        self.normalized_dim = normalized_dim\n",
    "        self.net = cv2.dnn.readNetFromCaffe(self.configFile, self.modelFile)\n",
    "        \n",
    "    def extract_random_faces(self, filename, num_faces):\n",
    "        captured_faces = []\n",
    "        iterations = 0\n",
    "        v_cap = cv2.VideoCapture(filename)\n",
    "        v_length = int(v_cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        \n",
    "        while len(captured_faces) < num_faces and iterations < self.max_interations:\n",
    "            iterations += 1\n",
    "            v_cap.set(1, np.random.randint(v_length)-1)\n",
    "            \n",
    "            ret, img = v_cap.read()\n",
    "        \n",
    "            if ret == True:\n",
    "                (h, w) = img.shape[:2]\n",
    "                blob = cv2.dnn.blobFromImage(cv2.resize(img, (300, 300)), 1.0, (300, 300), (103.93, 116.77, 123.68))\n",
    "                self.net.setInput(blob)\n",
    "                detections = self.net.forward()\n",
    "                for i in range(detections.shape[2]):\n",
    "                    confidence = detections[0, 0, i, 2]            \n",
    "                    if confidence > self.conf_threshold:\n",
    "                        box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
    "                        (x1, y1, x2, y2) = box.astype(\"int\")\n",
    "                        face=img[y1:y2, x1:x2]\n",
    "                        \n",
    "                        # normlize\n",
    "                        face = cv2.resize(face, self.normalized_dim)\n",
    "                        captured_faces.append(face)\n",
    "        \n",
    "        # When everything done, release the video capture and video write objects\n",
    "        v_cap.release()\n",
    "    \n",
    "        return captured_faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dfdc_train_part_11\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "for root, dirs, files in os.walk('../videos', topdown=False):\n",
    "    for name in dirs:\n",
    "        print(name)\n",
    "        dfdir = pd.read_json('../videos/' + name + '/metadata.json')\n",
    "        dfdir = dfdir.T\n",
    "        dfdir['dir'] = name\n",
    "        df = df.append(dfdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>original</th>\n",
       "      <th>split</th>\n",
       "      <th>dir</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2118</td>\n",
       "      <td>1759</td>\n",
       "      <td>2118</td>\n",
       "      <td>2118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2</td>\n",
       "      <td>359</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>FAKE</td>\n",
       "      <td>qifhccqwpi.mp4</td>\n",
       "      <td>train</td>\n",
       "      <td>dfdc_train_part_11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1759</td>\n",
       "      <td>30</td>\n",
       "      <td>2118</td>\n",
       "      <td>2118</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       label        original  split                 dir\n",
       "count   2118            1759   2118                2118\n",
       "unique     2             359      1                   1\n",
       "top     FAKE  qifhccqwpi.mp4  train  dfdc_train_part_11\n",
       "freq    1759              30   2118                2118"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>original</th>\n",
       "      <th>split</th>\n",
       "      <th>dir</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>envmivjahd.mp4</th>\n",
       "      <td>FAKE</td>\n",
       "      <td>dqavjmidxr.mp4</td>\n",
       "      <td>train</td>\n",
       "      <td>dfdc_train_part_11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ynsxzcicxv.mp4</th>\n",
       "      <td>REAL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>train</td>\n",
       "      <td>dfdc_train_part_11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mesyfmgozo.mp4</th>\n",
       "      <td>FAKE</td>\n",
       "      <td>wotgiryojo.mp4</td>\n",
       "      <td>train</td>\n",
       "      <td>dfdc_train_part_11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gwnxqtenem.mp4</th>\n",
       "      <td>FAKE</td>\n",
       "      <td>zjhmmibena.mp4</td>\n",
       "      <td>train</td>\n",
       "      <td>dfdc_train_part_11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vnzfjmxalx.mp4</th>\n",
       "      <td>FAKE</td>\n",
       "      <td>jrzsengxux.mp4</td>\n",
       "      <td>train</td>\n",
       "      <td>dfdc_train_part_11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>torlpqwpfj.mp4</th>\n",
       "      <td>FAKE</td>\n",
       "      <td>oimivjeigb.mp4</td>\n",
       "      <td>train</td>\n",
       "      <td>dfdc_train_part_11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jbbysdmnwr.mp4</th>\n",
       "      <td>FAKE</td>\n",
       "      <td>iohuzwvefi.mp4</td>\n",
       "      <td>train</td>\n",
       "      <td>dfdc_train_part_11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>umdojzbwds.mp4</th>\n",
       "      <td>FAKE</td>\n",
       "      <td>chdbpzgrpy.mp4</td>\n",
       "      <td>train</td>\n",
       "      <td>dfdc_train_part_11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zqriqgfsnb.mp4</th>\n",
       "      <td>FAKE</td>\n",
       "      <td>onygmnjhph.mp4</td>\n",
       "      <td>train</td>\n",
       "      <td>dfdc_train_part_11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>blruhiftcw.mp4</th>\n",
       "      <td>FAKE</td>\n",
       "      <td>bufydtkvxt.mp4</td>\n",
       "      <td>train</td>\n",
       "      <td>dfdc_train_part_11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               label        original  split                 dir\n",
       "envmivjahd.mp4  FAKE  dqavjmidxr.mp4  train  dfdc_train_part_11\n",
       "ynsxzcicxv.mp4  REAL             NaN  train  dfdc_train_part_11\n",
       "mesyfmgozo.mp4  FAKE  wotgiryojo.mp4  train  dfdc_train_part_11\n",
       "gwnxqtenem.mp4  FAKE  zjhmmibena.mp4  train  dfdc_train_part_11\n",
       "vnzfjmxalx.mp4  FAKE  jrzsengxux.mp4  train  dfdc_train_part_11\n",
       "torlpqwpfj.mp4  FAKE  oimivjeigb.mp4  train  dfdc_train_part_11\n",
       "jbbysdmnwr.mp4  FAKE  iohuzwvefi.mp4  train  dfdc_train_part_11\n",
       "umdojzbwds.mp4  FAKE  chdbpzgrpy.mp4  train  dfdc_train_part_11\n",
       "zqriqgfsnb.mp4  FAKE  onygmnjhph.mp4  train  dfdc_train_part_11\n",
       "blruhiftcw.mp4  FAKE  bufydtkvxt.mp4  train  dfdc_train_part_11"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "/root/opencv-3.4.0/modules/dnn/src/caffe/caffe_io.cpp:1145: error: (-2) FAILED: ReadProtoFromTextFile(param_file, param). Failed to parse NetParameter file: ../models/deploy.prototxt in function ReadNetParamsFromTextFileOrDie\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-b4e1c3ab735a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFaceDetector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-b2c5c69ee1aa>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, modelFile, configFile, max_interations, conf_threshold, normalized_dim)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconf_threshold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconf_threshold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalized_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalized_dim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadNetFromCaffe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfigFile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodelFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextract_random_faces\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_faces\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: /root/opencv-3.4.0/modules/dnn/src/caffe/caffe_io.cpp:1145: error: (-2) FAILED: ReadProtoFromTextFile(param_file, param). Failed to parse NetParameter file: ../models/deploy.prototxt in function ReadNetParamsFromTextFileOrDie\n"
     ]
    }
   ],
   "source": [
    "fd=FaceDetector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:09<00:00,  4.15s/it]\n"
     ]
    }
   ],
   "source": [
    "nr = 3\n",
    "nf = 4\n",
    "faces = np.empty(shape=(0,32,32,3), dtype=np.int8)\n",
    "labels = np.empty(shape=(0, 1), dtype=\"<U5\")\n",
    "for index, row in tqdm(df.sample(nr).iterrows(), total=nr):\n",
    "    images = fd.extract_random_faces('../videos/' + row.dir + '/' + index, nf)\n",
    "    if len(images) > 0:\n",
    "        faces = np.append(faces,images,axis=0)\n",
    "        labels = np.append(labels, np.full(shape=(len(images),1), fill_value=row.label, dtype=\"<U5\"),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(faces) == len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('../data/train',faces=faces, labels=labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
